{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "809ffc1e-dcce-48b2-80db-805a235c5634",
   "metadata": {},
   "source": [
    "## Instantiate a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c23a5b2-a41d-41e9-83b3-ca5b6bfb09f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/21 15:11:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[Stage 0:====================================>                      (5 + 3) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MyApp\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "# check if works\n",
    "dftest = spark.range(100)\n",
    "print(dftest.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac122f0a-3a84-47a3-84fe-e2b1b8e9d08f",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ff6aa7b-4046-4cb8-ace7-c54bec595a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "Cardinality: 541909\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = spark.read.option(\"delimiter\", \",\").option(\"header\", True).csv(\"../data/data.csv\")\n",
    "df.printSchema()\n",
    "cardinality = df.count()\n",
    "print(\"Cardinality:\", cardinality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293c9c7-a5ae-4f87-bdae-e8f9b113eed8",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e0a04d3-12d8-45e5-8764-32f69a9d3d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any null records?\n",
      "+-------------+-------------+---------------+------------+---------------+-------------+--------------+-----------+\n",
      "|InvoiceNo [%]|StockCode [%]|Description [%]|Quantity [%]|InvoiceDate [%]|UnitPrice [%]|CustomerID [%]|Country [%]|\n",
      "+-------------+-------------+---------------+------------+---------------+-------------+--------------+-----------+\n",
      "|          0.0|          0.0|           0.27|         0.0|            0.0|          0.0|         24.93|        0.0|\n",
      "+-------------+-------------+---------------+------------+---------------+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Any null records?\")\n",
    "(df.select(\n",
    "        [\n",
    "            F.round((F.sum(F.col(col).isNull().cast(\"int\"))/F.lit(cardinality)*100), 2)\n",
    "            .alias(f\"{col} [%]\")\n",
    "            for col in df.columns\n",
    "        ]\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b12f6bfb-d8c7-4462-bc66-514baebd2511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the two continuous attributes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|         UnitPrice|          Quantity|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            541909|            541909|\n",
      "|   mean|4.6111136260897085|  9.55224954743324|\n",
      "| stddev| 96.75985306117963|218.08115785023438|\n",
      "|    min|         -11062.06|                -1|\n",
      "|    25%|              1.25|               1.0|\n",
      "|    50%|              2.08|               3.0|\n",
      "|    75%|              4.13|              10.0|\n",
      "|    max|             99.96|               992|\n",
      "+-------+------------------+------------------+\n",
      "\n",
      "Distribution of the negative Quantity\n",
      "+-------+------------------+\n",
      "|summary|          Quantity|\n",
      "+-------+------------------+\n",
      "|  count|             10624|\n",
      "|   mean|-45.60721009036145|\n",
      "| stddev|   1092.2142164236|\n",
      "|    min|                -1|\n",
      "|    25%|             -10.0|\n",
      "|    50%|              -2.0|\n",
      "|    75%|              -1.0|\n",
      "|    max|              -990|\n",
      "+-------+------------------+\n",
      "\n",
      "Distribution of the negative UnitPrice\n",
      "+-------+---------+\n",
      "|summary|UnitPrice|\n",
      "+-------+---------+\n",
      "|  count|        2|\n",
      "|   mean|-11062.06|\n",
      "| stddev|      0.0|\n",
      "|    min|-11062.06|\n",
      "|    25%|-11062.06|\n",
      "|    50%|-11062.06|\n",
      "|    75%|-11062.06|\n",
      "|    max|-11062.06|\n",
      "+-------+---------+\n",
      "\n",
      "Any negative UnitPrice for back_transactions?\n",
      "+----------------+\n",
      "|count(UnitPrice)|\n",
      "+----------------+\n",
      "|               0|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of the two continuous attributes\")\n",
    "df.select([\"UnitPrice\", \"Quantity\"]).summary().show()\n",
    "\n",
    "# back_transactions are those with negative Quantity\n",
    "df.select(\"*\").filter(F.col(\"Quantity\") < 0).createOrReplaceTempView(\"back_transactions\")\n",
    "\n",
    "print(\"Distribution of the negative Quantity\")\n",
    "back_transactions = spark.table(\"back_transactions\").select(F.col(\"Quantity\")).summary().show()\n",
    "\n",
    "print(\"Distribution of the negative UnitPrice\")\n",
    "df.select(\"UnitPrice\").filter(F.col(\"UnitPrice\") < 0).summary().show()\n",
    "\n",
    "print(\"Any negative UnitPrice for back_transactions?\")\n",
    "spark.sql(\"SELECT COUNT(UnitPrice) FROM back_transactions WHERE UnitPrice < 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08d47414-2c28-4d9b-9d9a-e68aeb79c949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ghost customers (i.e. null CustomerID) distribution of Quantity and UnitPrice\n",
      "+-------+-----------------+------------------+\n",
      "|summary|        UnitPrice|          Quantity|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|           135080|            135080|\n",
      "|   mean|8.076576917382749|1.9955729937814628|\n",
      "| stddev|151.9008162787955| 66.69615267858345|\n",
      "|    min|        -11062.06|                -1|\n",
      "|    25%|             1.63|               1.0|\n",
      "|    50%|             3.29|               1.0|\n",
      "|    75%|              5.4|               3.0|\n",
      "|    max|            99.96|                99|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ghost customers (i.e. null CustomerID) distribution of Quantity and UnitPrice\")\n",
    "(df.select([\"UnitPrice\", \"Quantity\", \"CustomerID\"])\n",
    "    .filter(F.col(\"CustomerID\").isNull() == True)\n",
    "    .select([\"UnitPrice\", \"Quantity\"])\n",
    "    .summary()\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ebdb6-fbc0-4ec0-ba15-b7e8e5dbdacb",
   "metadata": {},
   "source": [
    "## Data engineering\n",
    "* Create new attributes out of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c338d9ea-4b2d-485c-967a-7cd6cd5db7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global revenues, including back transactions: 9747747.933999127\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Revenue\", df.UnitPrice * df.Quantity)\n",
    "tot_revenue = df.agg(F.sum(\"Revenue\")).collect()[0][0]\n",
    "print(\"Global revenues, including back transactions:\",tot_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e86e5e-4409-48f6-bb1b-10aa00f2ac1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
