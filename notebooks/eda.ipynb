{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "809ffc1e-dcce-48b2-80db-805a235c5634",
   "metadata": {},
   "source": [
    "## Instantiate a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c23a5b2-a41d-41e9-83b3-ca5b6bfb09f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as sf\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MyApp\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "# check if works\n",
    "dftest = spark.range(100)\n",
    "print(dftest.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac122f0a-3a84-47a3-84fe-e2b1b8e9d08f",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff6aa7b-4046-4cb8-ace7-c54bec595a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "Cardinality: 541909\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = spark.read.option(\"delimiter\", \",\").option(\"header\", True).csv(\"../data/data.csv\")\n",
    "df.printSchema()\n",
    "print(\"Cardinality:\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293c9c7-a5ae-4f87-bdae-e8f9b113eed8",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0a04d3-12d8-45e5-8764-32f69a9d3d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any null records?\n",
      "+-------------+-------------+---------------+------------+---------------+-------------+--------------+-----------+\n",
      "|InvoiceNo [%]|StockCode [%]|Description [%]|Quantity [%]|InvoiceDate [%]|UnitPrice [%]|CustomerID [%]|Country [%]|\n",
      "+-------------+-------------+---------------+------------+---------------+-------------+--------------+-----------+\n",
      "|          0.0|          0.0|           0.27|         0.0|            0.0|          0.0|         24.93|        0.0|\n",
      "+-------------+-------------+---------------+------------+---------------+-------------+--------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"Any null records?\")\n",
    "(df.select(\n",
    "        [\n",
    "            sf.round((sf.sum(sf.col(col).isNull().cast(\"int\"))/sf.lit(df.count())*100), 2)\n",
    "            .alias(f\"{col} [%]\")\n",
    "            for col in df.columns\n",
    "        ]\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12f6bfb-d8c7-4462-bc66-514baebd2511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the two continuous attributes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|         UnitPrice|          Quantity|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            541909|            541909|\n",
      "|   mean|4.6111136260897085|  9.55224954743324|\n",
      "| stddev| 96.75985306117963|218.08115785023438|\n",
      "|    min|         -11062.06|                -1|\n",
      "|    25%|              1.25|               1.0|\n",
      "|    50%|              2.08|               3.0|\n",
      "|    75%|              4.13|              10.0|\n",
      "|    max|             99.96|               992|\n",
      "+-------+------------------+------------------+\n",
      "\n",
      "Distribution of the negative Quantity\n",
      "+-------+------------------+\n",
      "|summary|          Quantity|\n",
      "+-------+------------------+\n",
      "|  count|             10624|\n",
      "|   mean|-45.60721009036145|\n",
      "| stddev|   1092.2142164236|\n",
      "|    min|                -1|\n",
      "|    25%|             -10.0|\n",
      "|    50%|              -2.0|\n",
      "|    75%|              -1.0|\n",
      "|    max|              -990|\n",
      "+-------+------------------+\n",
      "\n",
      "Distribution of the negative UnitPrice\n",
      "+-------+---------+\n",
      "|summary|UnitPrice|\n",
      "+-------+---------+\n",
      "|  count|        2|\n",
      "|   mean|-11062.06|\n",
      "| stddev|      0.0|\n",
      "|    min|-11062.06|\n",
      "|    25%|-11062.06|\n",
      "|    50%|-11062.06|\n",
      "|    75%|-11062.06|\n",
      "|    max|-11062.06|\n",
      "+-------+---------+\n",
      "\n",
      "Any negative UnitPrice for back_transactions?\n",
      "+----------------+\n",
      "|count(UnitPrice)|\n",
      "+----------------+\n",
      "|               0|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of the two continuous attributes\")\n",
    "df.select([\"UnitPrice\", \"Quantity\"]).summary().show()\n",
    "\n",
    "# back_transactions are those with negative Quantity\n",
    "df.select(\"*\").filter(sf.col(\"Quantity\") < 0).createOrReplaceTempView(\"back_transactions\")\n",
    "\n",
    "print(\"Distribution of the negative Quantity\")\n",
    "back_transactions = spark.table(\"back_transactions\").select(sf.col(\"Quantity\")).summary().show()\n",
    "\n",
    "print(\"Distribution of the negative UnitPrice\")\n",
    "df.select(\"UnitPrice\").filter(sf.col(\"UnitPrice\") < 0).summary().show()\n",
    "\n",
    "print(\"Any negative UnitPrice for back_transactions?\")\n",
    "spark.sql(\"SELECT COUNT(UnitPrice) FROM back_transactions WHERE UnitPrice < 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d47414-2c28-4d9b-9d9a-e68aeb79c949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ghost customers (i.e. null CustomerID) distribution of Quantity and UnitPrice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:==============>                                           (2 + 6) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|        UnitPrice|          Quantity|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|           135080|            135080|\n",
      "|   mean|8.076576917382749|1.9955729937814628|\n",
      "| stddev|151.9008162787955| 66.69615267858345|\n",
      "|    min|        -11062.06|                -1|\n",
      "|    25%|             1.63|               1.0|\n",
      "|    50%|             3.29|               1.0|\n",
      "|    75%|              5.4|               3.0|\n",
      "|    max|            99.96|                99|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"Ghost customers (i.e. null CustomerID) distribution of Quantity and UnitPrice\")\n",
    "(df.select([\"UnitPrice\", \"Quantity\", \"CustomerID\"])\n",
    "    .filter(sf.col(\"CustomerID\").isNull() == True)\n",
    "    .select([\"UnitPrice\", \"Quantity\"])\n",
    "    .summary()\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ebdb6-fbc0-4ec0-ba15-b7e8e5dbdacb",
   "metadata": {},
   "source": [
    "## Data engineering\n",
    "* Drop rows with negative UnitPrice, no interpretation available.\n",
    "* Create new attributes out of the original dataset\n",
    "  1. Revenue = Quantity*UnitPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6d10709-d039-47d1-930b-68dc9a18b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinality: 541907\n"
     ]
    }
   ],
   "source": [
    "clean_df = df.filter(sf.col(\"UnitPrice\") >= 0)\n",
    "print(\"Cardinality:\", clean_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c338d9ea-4b2d-485c-967a-7cd6cd5db7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global revenues, including back transactions: 9769872.053999126\n"
     ]
    }
   ],
   "source": [
    "clean_df = clean_df.withColumn(\"Revenue\", df.UnitPrice * df.Quantity)\n",
    "tot_revenue = clean_df.agg(sf.sum(\"Revenue\")).collect()[0][0]\n",
    "print(\"Global revenues, including back transactions:\",tot_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3e86e5e-4409-48f6-bb1b-10aa00f2ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much revenue do ghost customers bring?\n",
      "+------------------------------+\n",
      "|ghost_customers_revenues_share|\n",
      "+------------------------------+\n",
      "|             15.04427316833096|\n",
      "+------------------------------+\n",
      "\n",
      "Distribution of revenues from ghost customers\n",
      "+-------+------------------+\n",
      "|summary|           Revenue|\n",
      "+-------+------------------+\n",
      "|  count|            135078|\n",
      "|   mean|10.881166733295247|\n",
      "| stddev|152.11456887118285|\n",
      "|    min|         -17836.46|\n",
      "|    25%|              2.46|\n",
      "|    50%|              4.96|\n",
      "|    75%|             10.79|\n",
      "|    max|          13541.33|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"How much revenue do ghost customers bring?\")\n",
    "clean_df.createOrReplaceTempView(\"clean_df\")\n",
    "spark.sql(\"SELECT 100.*SUM(CASE WHEN CustomerID IS NULL THEN Revenue ELSE 0 END)/SUM(Revenue) AS ghost_customers_revenues_share FROM clean_df\").show()\n",
    "\n",
    "print(\"Distribution of revenues from ghost customers\")\n",
    "(clean_df\n",
    "    .select([\"CustomerID\", \"Revenue\"])\n",
    "    .filter(sf.col(\"CustomerID\").isNull())\n",
    "    .select([\"Revenue\"])\n",
    "    .summary()\n",
    "    .show()\n",
    ")\n",
    "\n",
    "no_ghosts = clean_df.filter(sf.col(\"CustomerID\").isNull() == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e230a6d-b31e-44b8-9d7d-ef8495530c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|   InvoiceDate|\n",
      "+--------------+\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:28|\n",
      "|12/1/2010 8:28|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "|12/1/2010 8:34|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_ghosts.select(\"InvoiceDate\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ac30e25-239a-4288-848d-22be5d0d3caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse InvoiceDate attribute from string to datetime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"Parse InvoiceDate attribute from string to datetime\")\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pyspark.sql import types as st\n",
    "\n",
    "def parse_datetime(_dt: str):\n",
    "    try:\n",
    "        _dt = re.sub(r'(\\d+)/(\\d+)/(\\d+) (\\d+):(\\d+)', lambda m: f\"{int(m.group(1)):02d}/{int(m.group(2)):02d}/{m.group(3)} {int(m.group(4)):02d}:{m.group(5)}\", _dt)\n",
    "        return datetime.strptime(_dt, \"%m/%d/%Y %H:%M\")\n",
    "    except ValueError:\n",
    "        return None\n",
    "parse_datetime_udf = sf.udf(parse_datetime, st.TimestampType())\n",
    "\n",
    "no_ghosts = no_ghosts.withColumn(\"parsedInvoiceDate\", parse_datetime_udf(sf.col(\"InvoiceDate\")))\n",
    "assert no_ghosts.filter(sf.col(\"parsedInvoiceDate\").isNull()).count() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c4546-4348-40ff-a401-9bb32964afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 90\n",
    "\n",
    "print(f\"Evaluate Recency by {days} days\")\n",
    "recency_by_customer = (no_ghosts\n",
    "                        .filter(sf.col(\"parsedInvoiceDate\") >= sf.sub_date(sf.current_date(), days))\n",
    "                        .groupBy(\"customerID\")\n",
    "                        .agg()\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
